### üéØ Plan Completo de Desarrollo AFS - Paso a Paso
üìä Visi√≥n General

Total: 45 conversaciones organizadas en 10 fases

Cada conversaci√≥n incluye:
    ‚úÖ Documentos exactos a compartir
    ‚úÖ C√≥didocker compose exec backend go espec√≠fico a crear
    ‚úÖ Validaci√≥n concreta
    ‚úÖ Criterio de "listo para continuar"

# üèóÔ∏è FASE 1: Setup Inicial y Base de Datos (3 conversaciones)

***Conversaci√≥n #1: Estructura de Proyecto y Configuraci√≥n***

Objetivo: Crear estructura de directorios, .env, docker-compose

Debes consultar estos doc para la tarea:
- 00-PROJECT-OVERVIEW.md (completo)
- 10-DEVELOPMENT-WORKFLOW.md (secciones: Project Structure, Environment Setup)

Prompt:
Contexto: Proyecto AFS - Sistema multi-agente para optimizaci√≥n de DB

Tarea: Setup inicial del proyecto

Crear:
1. Estructura de directorios completa (backend/ y frontend/)
2. Directorio `secrets/` para credenciales.
3. .env.example con todas las variables necesarias
4. docker-compose.yml con:
   - PostgreSQL 16
   - Redis 7
   - Backend (docker compose exec backend go con Air), configurado para montar el volumen de credenciales (`./secrets/application_default_credentials.json`) y usar la variable de entorno `GOOGLE_APPLICATION_CREDENTIALS`.
   - Frontend (React con Vite)
   - Caddy

Requisitos:
- Seguir estructura exacta de 10-DEVELOPMENT-WORKFLOW.md
- Health checks en todos los servicios
- Vol√∫menes para persistencia
- Variables de entorno seg√∫n doc

Output:
- √Årbol de directorios completo (comando mkdir -p)
- .env.example
- docker-compose.yml
- .gitignore (backend y frontend)

Validaci√≥n:
# Crear estructura
[ejecutar comandos mkdir -p del output]
# Verificar docker-compose
docker-compose config
# Debe mostrar configuraci√≥n sin errores

‚úÖ Listo si: docker-compose config ejecuta sin errores

***Conversaci√≥n #2: Migraciones Base de Datos (E-commerce)***

Debes consultar estos doc para la tarea:
- 00-PROJECT-OVERVIEW.md (secci√≥n Tech Stack)
- 02-DATA-MODEL.md (secci√≥n: Existing Tables)
- 10-DEVELOPMENT-WORKFLOW.md (secci√≥n: Database Management)

Tarea: Crear migration inicial para tablas e-commerce

Ubicaci√≥n: backend/migrations/001_initial_schema.sql

Tablas a crear (seg√∫n DATA-MODEL):
- users (id, email, created_at)
- orders (id, user_id, total, status, created_at)
- payments (id, order_id, amount, status, created_at)

Requisitos:
- Formato: -- +migrate Up / -- +migrate Down
- Foreign keys con CASCADE
- √çndices PRIMARY KEY
- Down migration completa

Output:
- 001_initial_schema.sql completo

Validaci√≥n:
# Iniciar servicios
docker-compose up -d postgres
# Aplicar migration
docker-compose exec postgres psql -U afs_user -d afs_dev \
  < backend/migrations/001_initial_schema.sql
# Verificar tablas
docker-compose exec postgres psql -U afs_user -d afs_dev -c "\dt"
# Debe mostrar: users, orders, payments

‚úÖ Listo si: Las 3 tablas existen en la BD

*** Conversaci√≥n #3: Migraciones AFS + Seeder ***

Debes consultar estos doc para la tarea:
- 02-DATA-MODEL.md (secci√≥n: New Tables AFS System)
- 10-DEVELOPMENT-WORKFLOW.md (secci√≥n: Seeding Data)

Tarea 1: Crear migration 002_afs_tables.sql

Tablas (seg√∫n DATA-MODEL completo):
- tasks
- agent_executions
- optimization_proposals
- benchmark_results
- consensus_decisions

Incluir:
- Todos los campos de cada tabla
- Foreign keys correctos
- JSONB para metadata/scores
- √çndices seg√∫n doc 02

Tarea 2: Crear seeder

Ubicaci√≥n: backend/scripts/seed/main.go

Funcionalidad:
- Conectar a BD
- Truncar tablas existentes
- Crear 1,000 users (gofakeit)
- Crear 10,000 orders
- Crear 10,000 payments
- Distribuci√≥n: 75% completed, 12.5% pending, 12.5% processing

Output:
- 002_afs_tables.sql (Up y Down)
- backend/scripts/seed/main.go
- backend/go.mod (dependencias: gofakeit, sqlx, pq)

Validaci√≥n:
# Aplicar migration
docker-compose exec postgres psql -U afs_user -d afs_dev \
  < backend/migrations/002_afs_tables.sql
# Verificar tablas AFS
docker-compose exec postgres psql -U afs_user -d afs_dev \
  -c "SELECT tablename FROM pg_tables WHERE schemaname='public';"
# Debe mostrar 8 tablas (3 + 5 nuevas)

# Ejecutar seeder
cd backend
docker compose exec backend go mod download
docker compose exec backend go run scripts/seed/main.go

# Verificar datos
docker-compose exec postgres psql -U afs_user -d afs_dev \
  -c "SELECT COUNT(*) FROM users; SELECT COUNT(*) FROM orders;"
# Debe mostrar: users=1000, orders=10000

‚úÖ Listo si: 8 tablas existen y datos seeded correctamente

### üéØ FASE 2: Domain Layer (6 conversaciones)

*** Conversaci√≥n #4: Domain Entities - Task ***

Debes consultar estos doc para la tarea:
- 00-PROJECT-OVERVIEW.md (secci√≥n: Code Quality Standards)
- 02-DATA-MODEL.md (secci√≥n: Table tasks)
- 03-SYSTEM-ARCHITECTURE.md (secci√≥n: Layer 1 Domain)

Tarea: Crear entidad Task en Domain Layer

Ubicaci√≥n: backend/internal/domain/entities/task.go

Estructura:
- Struct Task con todos los campos de tabla tasks
- Tipo TaskType (enum: query_optimization, schema_improvement, etc.)
- Tipo TaskStatus (enum: pending, in_progress, completed, failed)
- M√©todo Validate() error
- M√©todo CanTransitionTo(newStatus) bool
- M√©todo IsComplete() bool

Requisitos:
- Zero dependencias externas (solo stdlib)
- Validaci√≥n de business rules (query no vac√≠o, type v√°lido, etc.)
- Comentarios para funciones p√∫blicas
- Max 300 l√≠neas

Output:
- task.go completo
- task_test.go con tests de validaci√≥n y transiciones

Validaci√≥n:
cd backend
# Ejecutar tests
docker compose exec backend go test ./internal/domain/entities -v
# Debe pasar todos los tests
# Coverage debe ser >80%

docker compose exec backend go test ./internal/domain/entities -cover

‚úÖ Listo si: Tests pasan y coverage >80%

*** Conversaci√≥n #5: Domain Entities - Agent, Proposal, Benchmark ***

Debes consultar estos doc para la tarea:
- 02-DATA-MODEL.md (secciones: agent_executions, optimization_proposals, benchmark_results)
- 03-SYSTEM-ARCHITECTURE.md (Layer 1 Domain)
- 04-AGENT-SYSTEM.md (secci√≥n: Agent Interface Contract)

Prompt:

Tarea: Crear entidades relacionadas

Ubicaci√≥n: backend/internal/domain/entities/

Crear:

1. agent_execution.go
   - Struct AgentExecution
   - Enum AgentType (cerebro, operativo, bulk)
   - Enum ExecutionStatus (running, completed, failed)
   - Validaciones

2. optimization_proposal.go
   - Struct OptimizationProposal
   - Enum ProposalType (index, partitioning, materialized_view, etc.)
   - Struct EstimatedImpact (JSONB fields)
   - Validaciones (SQL commands no vac√≠os, etc.)

3. benchmark_result.go
   - Struct BenchmarkResult
   - Struct ExplainPlan (JSONB fields)
   - Validaciones (execution time positivo, etc.)

Requisitos:
- Zero dependencias externas
- Cada archivo max 300 l√≠neas
- Tests en *_test.go

Output:
- agent_execution.go + test
- optimization_proposal.go + test
- benchmark_result.go + test

Validaci√≥n:
docker compose exec backend go test ./internal/domain/entities/... -v -cover

# Todos los tests deben pasar
# Coverage >80% en cada archivo

‚úÖ Listo si: Tests pasan, coverage >80%

*** Conversaci√≥n #6: Domain Entities - Consensus ***

Debes consultar estos doc para la tarea:
- 02-DATA-MODEL.md (secci√≥n: consensus_decisions)
- 03-SYSTEM-ARCHITECTURE.md (Layer 1)
- 05-CONSENSUS-BENCHMARKING.md (secci√≥n: Score Calculation)

Tarea: Crear entidad ConsensusDecision

Ubicaci√≥n: backend/internal/domain/entities/consensus_decision.go
Incluir:
- Struct ConsensusDecision
- Struct ProposalScore (performance, storage, complexity, risk, weighted_total)
- Struct ScoringCriteria (weights configurables)
- M√©todo CalculateWeightedTotal(scores) float64
- Validaciones (weights suman 1.0, etc.)

Output:
- consensus_decision.go
- consensus_decision_test.go (tests de c√°lculo de scores)

Validaci√≥n:
docker compose exec backend go test ./internal/domain/entities/... -v -cover

# Tests de scoring deben pasar
# Verificar f√≥rmula: (perf*0.5) + (storage*0.2) + (complexity*0.2) + (risk*0.1)

‚úÖ Listo si: C√°lculos de scoring correctos

*** Conversaci√≥n #7: Domain Interfaces - Repositories ***

Debes consultar estos doc para la tarea:
- 02-DATA-MODEL.md (todas las tablas)
- 03-SYSTEM-ARCHITECTURE.md (Dependency Inversion, Repository Pattern)

Tarea: Definir interfaces de repositorios

Ubicaci√≥n: backend/internal/domain/interfaces/repositories.go
Interfaces a crear:
type TaskRepository interface {
    Create(ctx context.Context, task *Task) error
    GetByID(ctx context.Context, id int) (*Task, error)
    List(ctx context.Context, filters TaskFilters) ([]*Task, error)
    Update(ctx context.Context, task *Task) error
}

type AgentExecutionRepository interface {
    Create(ctx context.Context, exec *AgentExecution) error
    GetByID(ctx context.Context, id int) (*AgentExecution, error)
    GetByTaskID(ctx context.Context, taskID int) ([]*AgentExecution, error)
    Update(ctx context.Context, exec *AgentExecution) error
}

(Similar para: OptimizationRepository, BenchmarkRepository, ConsensusRepository)

Requisitos:
- Solo interfaces (sin implementaci√≥n)
- Context como primer par√°metro
- Error handling
- Filters structs para List operations

Output:
- repositories.go con todas las interfaces

Validaci√≥n:
# Verificar compilaci√≥n
docker compose exec backend go build ./internal/domain/interfaces
# No debe haber errores (solo interfaces, no ejecuta)

‚úÖ Listo si: Compila sin errores

*** Conversaci√≥n #8: Domain Values - Enums y Constants ***

Debes consultar estos doc para la tarea:
- 02-DATA-MODEL.md (enums documentados)
- 03-SYSTEM-ARCHITECTURE.md (Layer 1)

Tarea: Centralizar enums y constantes

Ubicaci√≥n: backend/internal/domain/values/
Crear:
1. task_status.go
   - Const para TaskStatus (Pending, InProgress, Completed, Failed)
   - Funci√≥n IsValid(status) bool
   - Funci√≥n String() string

2. agent_type.go
   - Const para AgentType (cerebro, operativo, bulk)
   - Funci√≥n GetSpecialization(agentType) AgentSpecialization

3. proposal_type.go
   - Const para ProposalType (Index, Partitioning, etc.)

Output:
- task_status.go
- agent_type.go  
- proposal_type.go
- Cada uno con tests de validaci√≥n

Validaci√≥n:
docker compose exec backend go test ./internal/domain/values/... -v
# Tests de enums deben pasar
‚úÖ Listo si: Tests pasan

*** Conversaci√≥n #9: Config Layer ***

Debes consultar estos doc para la tarea:
- 03-SYSTEM-ARCHITECTURE.md (Layer 5: Configuration)
- 10-DEVELOPMENT-WORKFLOW.md (Environment Variables)

Tarea: Implementar Configuration Layer
Ubicaci√≥n: backend/internal/config/
Crear:
1. config.go
   - Struct Config con todas las secciones:
     * Server (Port, Host, Environment, LogLevel)
     * Database (URL, MaxConnections)
     * Redis (URL, Password)
     * Vertex AI: ProjectID, Location, Model IDs, y la ruta al archivo de credenciales (GOOGLE_APPLICATION_CREDENTIALS) para la autenticaci√≥n ADC.
     * Tiger Cloud (UseTigerCloud, MainService, MCP URL)
   - Funci√≥n Load() (*Config, error) que lee de env vars
   - Validaci√≥n de campos requeridos

2. tiger.go
   - Struct TigerConfig
   - Funci√≥n para leer ~/.config/tiger/mcp-config.json

Output:
- config.go
- tiger.go
- config_test.go (test de validaci√≥n)

Validaci√≥n:
# Test con env vars
export VERTEX_PROJECT_ID=test
export POSTGRES_DB=test
docker compose exec backend go test ./internal/config -v
# Debe pasar validaci√≥n
‚úÖ Listo si: Config carga y valida correctamente

### ‚öôÔ∏è FASE 3: Infrastructure Layer (10 conversaciones)

*** Conversaci√≥n #10: MCP Client - Base ***

Debes consultar estos doc para la tarea:
- 06-TIGER-CLOUD-MCP.md (secciones: MCP Protocol, Request/Response)
- 03-SYSTEM-ARCHITECTURE.md (Infrastructure Layer)
Tarea: Implementar MCP Client base

Ubicaci√≥n: backend/internal/infrastructure/mcp/client.go
Funcionalidad:
- Struct MCPClient con http.Client y config
- M√©todo Connect() error (test conexi√≥n)
- M√©todo ExecuteQuery(serviceID, sql) (QueryResult, error)
- M√©todo Close() error
- Retry logic con exponential backoff (3 attempts)
- Timeout handling

Request format seg√∫n doc 06
Response parsing

Output:
- client.go
- client_test.go (con mocks)

Validaci√≥n:
# Test unitario (con mock HTTP)
docker compose exec backend go test ./internal/infrastructure/mcp -v -run TestMCPClient
# Debe pasar sin llamar API real
‚úÖ Listo si: Tests con mocks pasan

*** Conversaci√≥n #11: MCP Client - Service Management***

Debes consultar estos doc para la tarea:
- 06-TIGER-CLOUD-MCP.md (secciones: Fork Operations, Service Management)

Tarea: Agregar operaciones de fork management
Ubicaci√≥n: backend/internal/infrastructure/mcp/service.go
M√©todos:
- CreateFork(parent, name) (forkID, error)
- DeleteFork(serviceID) error
- ListForks(parent) ([]ServiceInfo, error)
- GetServiceInfo(serviceID) (ServiceInfo, error)
Naming convention: afs-fork-{agent}-task{id}-{timestamp}
Output:
- service.go
- service_test.go

Validaci√≥n:
docker compose exec backend go test ./internal/infrastructure/mcp -v -run TestFork
# Tests con mock deben pasar
‚úÖ Listo si: Fork operations mockeadas funcionan

*** Conversaci√≥n #12: LLM Client - Vertex AI (Interface y Modelos) ***

Debes consultar estos doc para la tarea:
- 07-LLM-INTEGRATION.md (secciones: Cliente Unificado Vertex, Modelos)
- 03-SYSTEM-ARCHITECTURE.md (Infrastructure)
Tarea: Implementar LLM Client unificado (Vertex) con selecci√≥n de modelo
Ubicaci√≥n: backend/internal/infrastructure/llm/
Crear:
1. client.go (interface)
   type LLMClient interface {
       SendMessage(prompt, system string) (string, error)
       SendMessageWithJSON(prompt, system string) (map[string]interface{}, error)
       GetUsage() (inputTokens, outputTokens int)
   }
2. vertex_client.go
   - Implementa LLMClient
   - Selecci√≥n de modelo: gemini-2.5-pro | gemini-2.5-flash | gemini-2.0-flash
   - JSON parsing con markdown fence removal
   - Error handling seg√∫n doc 07
Output:
- client.go (interface)
- vertex_client.go (implementation)
- vertex_client_test.go (con mock HTTP)

Validaci√≥n:
# Test unitario (con mock HTTP)
docker compose exec backend go test ./internal/infrastructure/llm -v -run TestVertexClient
# Mock debe simular una respuesta de Vertex AI
# JSON parsing debe extraer correctamente
‚úÖ Listo si: Tests pasan, JSON parsing funciona

*** Conversaci√≥n #13: LLM Client - Modelos Vertex adicionales ***

Debes consultar estos doc para la tarea:
- 07-LLM-INTEGRATION.md (secciones: Modelos soportados en Vertex)

Tarea: A√±adir soporte de modelos adicionales en VertexClient
Ubicaci√≥n: backend/internal/infrastructure/llm/
Crear:
1. Extender vertex_client.go para modelos:
   - gemini-2.5-pro
   - gemini-2.5-flash
   - gemini-2.0-flash

Output:
- vertex_client_test.go (tests por modelo)

Validaci√≥n:
docker compose exec backend go test ./internal/infrastructure/llm/... -v
# VertexClient debe pasar tests mockeados para los 3 modelos
‚úÖ Listo si: 3 clients funcionan con mocks

*** Conversaci√≥n #14: Database - Repository Base ***

Debes consultar estos doc para la tarea:
- 02-DATA-MODEL.md (todas las tablas)
- 03-SYSTEM-ARCHITECTURE.md (Repository Pattern)

Tarea: Implementar TaskRepository
Ubicaci√≥n: backend/internal/infrastructure/database/repositories/task_repository.go
Implementaci√≥n:
- Struct PostgresTaskRepository con *sqlx.DB
- Implementar TaskRepository interface
- CRUD operations con SQL queries
- Error handling
- Context propagation
Output:
- task_repository.go
- task_repository_test.go (con test DB en Docker)

Validaci√≥n:
# Iniciar test DB
docker-compose up -d postgres
# Aplicar migrations
docker-compose exec postgres psql -U afs_user -d afs_dev < backend/migrations/001_initial_schema.sql
docker-compose exec postgres psql -U afs_user -d afs_dev < backend/migrations/002_afs_tables.sql
# Run tests
docker compose exec backend go test ./internal/infrastructure/database/repositories -v -run TestTaskRepository
# Debe crear/leer/actualizar tasks en DB real
‚úÖ Listo si: CRUD operations funcionan en DB real

*** Conversaci√≥n #15: Database - Resto de Repositories ***

Debes consultar estos doc para la tarea:
- 02-DATA-MODEL.md (tablas relacionadas)

Tarea: Implementar repositories restantes
Ubicaci√≥n: backend/internal/infrastructure/database/repositories/
Crear:
- agent_execution_repository.go
- optimization_repository.go
- benchmark_repository.go
- consensus_repository.go
Cada uno implementa su interface del domain
SQL queries seg√∫n schema en DATA-MODEL
Output:
- 4 archivos _repository.go
- 4 archivos _repository_test.go

Validaci√≥n:
docker compose exec backend go test ./internal/infrastructure/database/repositories/... -v
# Todos los repositories deben pasar tests con DB real
‚úÖ Listo si: 5 repositories funcionan

*** Conversaci√≥n #16: Agent Base Implementation ***

Debes consultar estos doc para la tarea:
- 04-AGENT-SYSTEM.md (secciones: Agent Interface, BaseAgent)
- 03-SYSTEM-ARCHITECTURE.md (Agents Infrastructure)

Tarea: Implementar BaseAgent (shared logic)
Ubicaci√≥n: backend/internal/infrastructure/agents/base.go
Funcionalidad:
- Struct BaseAgent con MCPClient, LLMClient, Config
- M√©todo CreateFork(taskID) (forkID, error)
  * Genera nombre: afs-fork-{agent}-task{id}-{timestamp}
  * Llama MCP CreateFork
  * Registra en AgentExecutionRepository
- M√©todo DestroyFork(forkID) error
- Logging helpers
- Error handling helpers
Output:
- base.go
- base_test.go

Validaci√≥n:
docker compose exec backend go test ./internal/infrastructure/agents -v -run TestBase
# Mock MCP client
# Verificar fork naming convention
‚úÖ Listo si: BaseAgent funciona con mocks

*** Conversaci√≥n #17: Agent Implementation (gemini-2.5-pro) ***

Debes consultar estos doc para la tarea:
- 04-AGENT-SYSTEM.md (secci√≥n: gemini-2.5-pro, Prompt Templates)
- 01-BUSINESS-LOGIC.md (gemini-2.5-pro Execution)

Tarea: Implementar Agent para gemini-2.5-pro
Ubicaci√≥n: backend/internal/infrastructure/agents/gemini25pro_agent.go
Implementar Agent interface:
1. AnalyzeTask(task, forkID) (AnalysisResult, error)
   - Ejecuta EXPLAIN ANALYZE en fork (via MCP)
   - Construye prompt con contexto (EXPLAIN + schema)
   - Llama VertexClient con modelo gemini-2.5-pro
   - Parsea JSON response
   - Retorna AnalysisResult
2. ProposeOptimization(analysis, forkID) (OptimizationProposal, error)
   - Prompt para generar SQL (√≠ndices t√≠picamente)
   - Valida SQL generado
   - Estima impacto
   - Retorna Proposal
3. RunBenchmark(proposal, forkID) ([]BenchmarkResult, error)
   - Define 4 test queries (baseline, limit, filter, sort)
   - Ejecuta cada query 3 veces
   - Calcula promedios
   - Mide storage impact
   - Retorna results
Prompts seg√∫n doc 04 (templates espec√≠ficos de gemini-2.5-pro)
Output:
- gemini25pro_agent.go (max 300 l√≠neas, dividir si necesario)
- gemini25pro_agent_test.go
Validaci√≥n:
# Test con mocks (LLM y MCP mockeados)
docker compose exec backend go test ./internal/infrastructure/agents -v -run TestAgentGemini25Pro
# Verificar:
# - Prompt construction correcta
# - JSON parsing funciona
# - Benchmark suite ejecuta 4 queries
‚úÖ Listo si: Agent gemini-2.5-pro funciona end-to-end con mocks

*** Conversaci√≥n #18: Agents (gemini-2.5-flash y gemini-2.0-flash) ***

Debes consultar estos doc para la tarea:
- 04-AGENT-SYSTEM.md (secciones: gemini-2.5-flash y gemini-2.0-flash)
Tarea: Implementar Agents para gemini-2.5-flash y gemini-2.0-flash
Ubicaci√≥n: backend/internal/infrastructure/agents/
Siguiendo mismo patr√≥n que Cerebro pero con:
- Prompts espec√≠ficos de cada modelo (doc 04)
- Especializaci√≥n diferente:
  * gemini-2.5-flash: Partitioning, schema redesign, ejecuci√≥n r√°pida
  * gemini-2.0-flash: Materialized views, tareas masivas de bajo riesgo
Output:
- gemini25flash_agent.go + test
- gemini20flash_agent.go + test
Validaci√≥n:
docker compose exec backend go test ./internal/infrastructure/agents/... -v
# 3 agents (gemini-2.5-pro, gemini-2.5-flash, gemini-2.0-flash) deben pasar tests con mocks
‚úÖ Listo si: 3 agents completos y testeados

*** Conversaci√≥n #19: Agent Factory ***

Debes consultar estos doc para la tarea:
- 03-SYSTEM-ARCHITECTURE.md (Factory Pattern)
- 04-AGENT-SYSTEM.md (Agent Types)

Tarea: Crear Agent Factory
Ubicaci√≥n: backend/internal/infrastructure/agents/factory.go
Funcionalidad:
- Funci√≥n NewAgent(agentType, mcpClient, llmClient, config) (Agent, error)
- Switch por AgentType (gemini25pro, gemini25flash, gemini20flash)
- Inyecci√≥n de dependencias
- Error si agentType inv√°lido
Output:
- factory.go
- factory_test.go (verificar todos los tipos)

Validaci√≥n:
docker compose exec backend go test ./internal/infrastructure/agents -v -run TestFactory
# Debe crear instancias de gemini25pro, gemini25flash, gemini20flash
‚úÖ Listo si: Factory crea correctamente los 3 tipos

### üéÆ FASE 4: Use Cases Layer (8 conversaciones)

*** Conversaci√≥n #20: Task Service ***

Debes consultar estos doc para la tarea:
- 01-BUSINESS-LOGIC.md (Task Lifecycle)
- 03-SYSTEM-ARCHITECTURE.md (Use Cases Layer)

Tarea: Implementar TaskService
Ubicaci√≥n: backend/internal/usecases/task_service.go
M√©todos:
- CreateTask(task) (Task, error)
  * Valida task
  * Persiste en repository
  * Retorna task con ID
- GetTask(id) (Task, error)
- ListTasks(filters) ([]Task, error)
- UpdateTaskStatus(id, status) error
Requisitos:
- Validaci√≥n de business rules
- Context propagation
- Error handling
Output:
- task_service.go
- task_service_test.go (con mock repository)

Validaci√≥n:
docker compose exec backend go test ./internal/usecases -v -run TestTaskService
# Tests con mock repository deben pasar
‚úÖ Listo si: CRUD b√°sico de tasks funciona

*** Conversaci√≥n #21: Task Router ***

Debes consultar estos doc para la tarea:
- 01-BUSINESS-LOGIC.md (Task Routing)
- 04-AGENT-SYSTEM.md (Router, Routing Algorithm)

Tarea: Implementar Task Router
Ubicaci√≥n: backend/internal/usecases/router.go
Funcionalidad:
- Struct Router con AgentFactory
- M√©todo SelectAgents(task) ([]Agent, error)
  * Calcula complexity score (seg√∫n doc 04)
  * Aplica routing rules (prioridad, features, tama√±o tabla)
  * Retorna lista de agents
  * Genera rationale
Reglas seg√∫n doc 04 (solo Gemini):
- High priority ‚Üí asignar gemini-2.5-pro, gemini-2.5-flash y gemini-2.0-flash
- JOINs ‚Üí incluir gemini-2.5-flash
- Table >1M rows ‚Üí incluir gemini-2.5-flash
- Aggregations complejas ‚Üí incluir gemini-2.5-pro
Output:
- router.go
- router_test.go (test cada regla)

Validaci√≥n:
docker compose exec backend go test ./internal/usecases -v -run TestRouter
# Test scenarios:
# - Simple query ‚Üí 1 agent (gemini-2.5-flash)
# - JOIN query ‚Üí 2 agents (gemini-2.5-flash + gemini-2.5-pro)
# - High priority ‚Üí 3 agents (gemini-2.5-pro, gemini-2.5-flash, gemini-2.0-flash)
‚úÖ Listo si: Routing rules funcionan correctamente

*** Conversaci√≥n #22: Benchmark Runner ***

Debes consultar estos doc para la tarea:
- 05-CONSENSUS-BENCHMARKING.md (Benchmark Runner section completa)
- 01-BUSINESS-LOGIC.md (Agent Workflow - Benchmarking)

Tarea: Implementar BenchmarkRunner (orquestador)
Ubicaci√≥n: backend/internal/usecases/benchmark_runner.go
Funcionalidad:
- M√©todo EvaluateProposal(proposal, forkID) ([]BenchmarkResult, error)
  * Define benchmark suite (4 queries seg√∫n doc 05)
  * Ejecuta baseline (antes de aplicar proposal)
  * Aplica proposal SQL en fork
  * Ejecuta queries optimizadas (3 veces cada una)
  * Calcula promedios
  * Mide storage impact
  * Parsea EXPLAIN plans
  * Retorna array de results
Suite seg√∫n doc 05:
- Test 1: Original query
- Test 2: Con LIMIT 10
- Test 3: Con filtro adicional
- Test 4: Con ORDER BY
Output:
- benchmark_runner.go
- benchmark_runner_test.go

Validaci√≥n:
docker compose exec backend go test ./internal/usecases -v -run TestBenchmarkRunner
# Mock MCP client
# Verificar 4 queries ejecutadas
# Verificar c√°lculo de improvement %
‚úÖ Listo si: Benchmark suite ejecuta correctamente

*** Conversaci√≥n #23: Consensus Engine ***

Debes consultar estos doc para la tarea:
- 05-CONSENSUS-BENCHMARKING.md (Consensus Engine, Scoring Algorithm completo)
- 01-BUSINESS-LOGIC.md (Consensus Decision)

Tarea: Implementar Consensus Engine
Ubicaci√≥n: backend/internal/usecases/consensus_engine.go
Funcionalidad:
- M√©todo Decide(proposals, benchmarks, criteria) (ConsensusDecision, error)
Algoritmo seg√∫n doc 05:
1. Por cada proposal:
   - CalculatePerformanceScore (0-100 seg√∫n improvement %)
   - CalculateStorageScore (0-100 seg√∫n overhead MB)
   - CalculateComplexityScore (0-100 seg√∫n proposal type)
   - CalculateRiskScore (0-100 seg√∫n risk level) 
2. Calcular weighted_total:
   (perf √ó 0.5) + (storage √ó 0.2) + (complexity √ó 0.2) + (risk √ó 0.1)
3. Ordenar por weighted_total DESC
4. Seleccionar winner (rank 1)
5. Generar rationale (template doc 05)
Tie-breaking seg√∫n doc 05
Output:
- consensus_engine.go
- consensus_engine_test.go (con data de ejemplo doc 01)

Validaci√≥n:
docker compose exec backend go test ./internal/usecases -v -run TestConsensus
# Test case ejemplo del doc 01:
# cerebro: 93.0 pts (winner)
# gemini25pro: 78.5 pts
# bulk: 66.5 pts
# Verificar f√≥rmulas correctas
‚úÖ Listo si: Scoring y ranking funcionan seg√∫n ejemplo

*** Conversaci√≥n #24: Orchestrator - Parte 1 (Agent Execution) ***

Debes consultar estos doc para la tarea:
- 01-BUSINESS-LOGIC.md (Complete User Flow, steps 3-4)
- 03-SYSTEM-ARCHITECTURE.md (Orchestrator)
- 04-AGENT-SYSTEM.md (Parallel Coordination)

Tarea: Implementar Orchestrator - Fase 1 (Parallel Agent Execution)
Ubicaci√≥n: backend/internal/usecases/orchestrator.go
Struct Orchestrator con dependencias:
- Router
- AgentFactory
- Repositories (todos)
- MCPClient
- Config
M√©todo ExecuteAgentsInParallel(task, agents) ([]Proposal, []Benchmark, error):
1. Crear WaitGroup
2. Crear channels para results y errors
3. Por cada agent:
   - Spawn goroutine
   - Dentro goroutine:
     * CreateFork
     * AnalyzeTask
     * ProposeOptimization
     * RunBenchmark
     * Enviar results a channel
4. Wait for all
5. Recopilar results
6. Manejar errores parciales (1 de 3 falla = ok)
Timeout: 10 min por agent
Output:
- orchestrator.go (primera versi√≥n, solo ejecuci√≥n paralela)
- orchestrator_test.go (con mocks)

Validaci√≥n:
docker compose exec backend go test ./internal/usecases -v -run TestOrchestratorParallel
# Mock agents
# Verificar goroutines se ejecutan
# Verificar WaitGroup funciona
# Test error parcial (1 agent falla, 2 contin√∫an)
‚úÖ Listo si: Ejecuci√≥n paralela funciona

*** Conversaci√≥n #25: Orchestrator - Parte 2 (Consensus y Apply) ***

Debes consultar estos doc para la tarea:
- 01-BUSINESS-LOGIC.md (steps 5-6: Consensus y Apply)
- 05-CONSENSUS-BENCHMARKING.md (Apply to Main Database)

Tarea: Completar Orchestrator con Consensus y Apply
En orchestrator.go agregar:
1. M√©todo ApplyToMainDB(winningProposal) error:
   - Pre-validation checks
   - Execute SQL en main DB (via MCP)
   - Post-application validation
   - Record PITR timestamp
   - Update consensus.applied_to_main
2. M√©todo CleanupForks(forkIDs) error:
   - Por cada fork, llamar MCP DeleteFork
   - Log cleanup
3. M√©todo ExecuteTask(taskID) error (m√©todo principal):
   - Load task
   - Call Router
   - ExecuteAgentsInParallel
   - Call ConsensusEngine
   - ApplyToMainDB
   - CleanupForks
   - Update task status
Error handling en cada paso
Output:
- orchestrator.go (versi√≥n completa)
- Agregar tests de flujo completo

Validaci√≥n:
docker compose exec backend go test ./internal/usecases -v -run TestOrchestratorComplete
# Test end-to-end con todos los mocks
# Verificar flujo completo: router ‚Üí agents ‚Üí consensus ‚Üí apply ‚Üí cleanup

‚úÖ Listo si: Flujo completo funciona end-to-end

*** Conversaci√≥n #26: WebSocket Event Broadcaster ***

Debes consultar estos doc para la tarea:
- 08-API-SPECIFICATION.md (WebSocket API)
- 03-SYSTEM-ARCHITECTURE.md (Observer Pattern)

Tarea: Implementar WebSocket Hub
Ubicaci√≥n: backend/internal/usecases/websocket_hub.go
Funcionalidad:
- Struct Hub con:
  * clients map
  * broadcast channel
  * register/unregister channels
- M√©todo Run() (goroutine principal)
- M√©todo Broadcast(event) (emitir a todos los clients)
- Event types seg√∫n doc 08
Integraci√≥n con Orchestrator:
- Orchestrator llama hub.Broadcast en cada paso
Output:
- websocket_hub.go
- websocket_hub_test.go

Validaci√≥n:
docker compose exec backend go test ./internal/usecases -v -run TestWebSocketHub
# Test registro de clients
# Test broadcast a m√∫ltiples clients
‚úÖ Listo si: Hub broadcast funciona
